{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilevel Monte Carlo Path Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "# Add the path to the mlmc module to the python path\n",
    "sys.path.append(\"../src\")\n",
    "from mlmc import MLMC, MonteCarloEstimator\n",
    "from model import Model, BlackScholes, Heston\n",
    "from contract import Contract, EuropeanCall, AsianCall, Lookback, Digital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "interest_rate = 0.05\n",
    "initial_value = np.array([1.0, 0.04])\n",
    "sigma = 0.2\n",
    "lbd, xi, rho = 5.0, 0.25, -0.5\n",
    "\n",
    "bs = BlackScholes(interest_rate, np.array(initial_value[0]), sigma)\n",
    "heston = Heston(interest_rate, initial_value, sigma, lbd, xi, rho)\n",
    "\n",
    "# Contracts\n",
    "maturity = 1.0\n",
    "strike = 1.0\n",
    "\n",
    "ue_call = EuropeanCall(maturity, strike)\n",
    "asian_call = AsianCall(maturity, strike)\n",
    "lookback = Lookback(maturity, sigma)\n",
    "digital = Digital(maturity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paper_plots(mc: MonteCarloEstimator, model: Model, contract: Contract, target_errors: np.ndarray) -> None:\n",
    "    m = mc.m\n",
    "    sample_count, level = 10**6, 5\n",
    "\n",
    "    print(\"Computations for estimation of mean and variance...\")\n",
    "    estimator = mc.computations_for_plots(model, contract, sample_count, level)\n",
    "\n",
    "    log_means = np.log(np.cumsum(estimator[\"means\"])) / np.log(m)\n",
    "    log_means_diff = np.log(estimator[\"means\"][1:]) / np.log(m)\n",
    "    log_vars = np.log(np.cumsum(estimator[\"vars\"])) / np.log(m)\n",
    "    log_vars_diff = np.log(estimator[\"vars\"][1:]) / np.log(m)\n",
    "    log_means_richardson = np.log(estimator[\"means_richardson\"]) / np.log(m)\n",
    "\n",
    "    optimals_samples = []\n",
    "    optimals_samples_richardson = []\n",
    "    computationnal_costs = []\n",
    "    computationnal_costs_richardson = []\n",
    "    computationnal_costs_std = []\n",
    "    computationnal_costs_richardson_std = []\n",
    "    for target_error in target_errors:\n",
    "        print(\"Computing mlmc estimator without richardson extrapolation\")\n",
    "        estimator, samples = mc.compute_multilevel_estimator(model, contract, target_error, False)\n",
    "        optimals_samples.append(samples)\n",
    "\n",
    "        print(\"Computing mlmc estimator with richardson extrapolation\")\n",
    "        estimator, samples_richardson = mc.compute_multilevel_estimator(model, contract, target_error, True)\n",
    "        optimals_samples_richardson.append(samples_richardson)\n",
    "\n",
    "        costs = [samples[0]] + [samples[i] * (m**i + m ** (i - 1)) for i in range(1, len(samples))]\n",
    "        computationnal_costs.append(np.sum(costs))\n",
    "        costs_richardson = [samples_richardson[0]] + [\n",
    "            samples_richardson[i] * (m**i + m ** (i - 1)) for i in range(1, len(samples_richardson))\n",
    "        ]\n",
    "        computationnal_costs_richardson.append(np.sum(costs_richardson))\n",
    "\n",
    "        print(\"Computing standard estimator without richardson extrapolation\")\n",
    "        estimator, samples_std = mc.compute_standard_estimator(model, contract, target_error, False)\n",
    "        computationnal_costs_std.append(np.sum([s * m**i for i, s in enumerate(samples_std)]))\n",
    "\n",
    "        # print(\"Computing standard estimator with richardson extrapolation\")\n",
    "        # estimator, samples_std_richardson = mc.compute_standard_estimator(model, contract, target_error, True)\n",
    "        # computationnal_costs_richardson_std.append(np.sum([s * m**i for i, s in enumerate(samples_std_richardson)]))\n",
    "\n",
    "    epsilon_cost = np.array(computationnal_costs) * target_errors**2\n",
    "    epsilon_cost_richardson = np.array(computationnal_costs_richardson) * target_errors**2\n",
    "    epsilon_cost_std = np.array(computationnal_costs_std) * target_errors**2\n",
    "    # epsilon_cost_richardson_std = np.array(computationnal_costs_richardson_std) * target_errors**2\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 8), dpi=120)\n",
    "    l1 = np.arange(0, level)\n",
    "    l2 = np.arange(1, level)\n",
    "    l3 = np.arange(2, level)\n",
    "\n",
    "    # Top left\n",
    "    axs[0, 0].plot(l1, log_vars, \"-\", marker=\"x\", c=\"black\", label=\"$P_l$\")\n",
    "    axs[0, 0].plot(l2, log_vars_diff, \"--\", marker=\"x\", c=\"black\", label=\"$P_l-P_{l-1}$\")\n",
    "    axs[0, 0].set_ylabel(\"$log_M$ variance\")\n",
    "    axs[0, 0].set_xlabel(\"l\")\n",
    "    axs[0, 0].legend()\n",
    "\n",
    "    # Top right\n",
    "    axs[0, 1].plot(l1, log_means, \"-\", marker=\"x\", c=\"black\", label=\"$P_l$\")\n",
    "    axs[0, 1].plot(l2, log_means_diff, \"--\", marker=\"x\", c=\"black\", label=\"$P_l-P_{l-1}$\")\n",
    "    axs[0, 1].plot(l3, log_means_richardson, \"-.\", marker=\"x\", c=\"black\", label=\"$Y_l-Y_{l-1}/M$\")\n",
    "    axs[0, 1].set_xlabel(\"$l$\")\n",
    "    axs[0, 1].set_ylabel(\"$log_M |mean|$\")\n",
    "    axs[0, 1].legend()\n",
    "\n",
    "    # Bottom left\n",
    "    markers = [\"x\", \"o\", \"v\", \"s\", \"*\"]\n",
    "    for i, optimal_samples in enumerate(optimals_samples):\n",
    "        n = len(optimal_samples)\n",
    "        l = np.arange(start=0, stop=n, step=1)\n",
    "        axs[1, 0].plot(l, optimal_samples, \":\", marker=markers[i], c=\"black\", label=rf\"$\\epsilon = {target_error[i]}$\")\n",
    "        axs[1, 0].set_yscale(\"log\")\n",
    "\n",
    "    for i, optimal_samples in enumerate(optimals_samples_richardson):\n",
    "        n = len(optimal_samples)\n",
    "        l = np.arange(start=0, stop=n, step=1)\n",
    "        axs[1, 0].plot(l, optimal_samples, \"-.\", marker=markers[i], c=\"black\")\n",
    "        axs[1, 0].set_yscale(\"log\")\n",
    "\n",
    "    axs[1, 0].set_xlabel(\"$l$\")\n",
    "    axs[1, 0].set_ylabel(\"$N_l$\")\n",
    "    axs[1, 0].legend()\n",
    "\n",
    "    # Bottom right\n",
    "    axs[1, 1].plot(target_errors, epsilon_cost, \"--\", c=\"black\", marker=\"x\", label=\"MLMC\")\n",
    "    axs[1, 1].plot(target_errors, epsilon_cost_richardson, \"-.\", c=\"black\", marker=\"x\", label=\"MLMC ext\")\n",
    "    axs[1, 1].plot(target_errors, epsilon_cost_std, \":\", c=\"black\", marker=\"x\", label=\"std MC\")\n",
    "    # axs[1, 1].plot(\n",
    "    #     target_errors, epsilon_cost_richardson_std, color=\"black\", linestyle=\"-\", marker=\"x\", label=\"std MC ext\"\n",
    "    # )\n",
    "\n",
    "    axs[1, 1].set_xscale(\"log\")\n",
    "    axs[1, 1].set_yscale(\"log\")\n",
    "    axs[1, 1].set_ylabel(r\"$\\epsilon^2$cost\")\n",
    "    axs[1, 1].set_xlabel(r\"$\\epsilon$\")\n",
    "    axs[1, 1].legend()\n",
    "\n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLMC parameters\n",
    "max_level = 4\n",
    "default_sample_count = 10_000\n",
    "m = 4\n",
    "\n",
    "# For reproducibility\n",
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "mc = MonteCarloEstimator(max_level, m, default_sample_count, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations for estimation of mean and variance...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m plots \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target_errors, model, contract \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# plots.append(create_paper_plots(mc, model, contract, target_errors))\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     fig, _ \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_paper_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_errors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     fig\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     20\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "Cell \u001b[0;32mIn[3], line 6\u001b[0m, in \u001b[0;36mcreate_paper_plots\u001b[0;34m(mc, model, contract, target_errors)\u001b[0m\n\u001b[1;32m      3\u001b[0m sample_count, level \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputations for estimation of mean and variance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[43mmc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomputations_for_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m log_means \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(np\u001b[38;5;241m.\u001b[39mcumsum(estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(m)\n\u001b[1;32m      9\u001b[0m log_means_diff \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m:]) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(m)\n",
      "File \u001b[0;32m~/Developer/Projects/mlmc_simulation_path/notebooks/../src/mlmc.py:147\u001b[0m, in \u001b[0;36mMonteCarloEstimator.computations_for_plots\u001b[0;34m(self, model, contract, sample_count, level)\u001b[0m\n\u001b[1;32m    140\u001b[0m estimator \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([]),  \u001b[38;5;66;03m# E[Y_l]\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvars\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([]),  \u001b[38;5;66;03m# Var(Y_l)\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayoffs\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39marray([]),  \u001b[38;5;66;03m# P_l\u001b[39;00m\n\u001b[1;32m    144\u001b[0m }\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(level):\n\u001b[0;32m--> 147\u001b[0m     payoffs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_payoffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayoffs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayoffs\u001b[39m\u001b[38;5;124m\"\u001b[39m], payoffs)\n\u001b[1;32m    149\u001b[0m     estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(estimator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeans\u001b[39m\u001b[38;5;124m\"\u001b[39m], np\u001b[38;5;241m.\u001b[39mmean(payoffs))\n",
      "File \u001b[0;32m~/Developer/Projects/mlmc_simulation_path/notebooks/../src/mlmc.py:259\u001b[0m, in \u001b[0;36mMonteCarloEstimator._sample_payoffs\u001b[0;34m(self, sample_count, level)\u001b[0m\n\u001b[1;32m    256\u001b[0m dw_fine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrng\u001b[38;5;241m.\u001b[39mnormal(scale\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(dt_fine), size\u001b[38;5;241m=\u001b[39m(sample_count, m_fine, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdimension))\n\u001b[1;32m    257\u001b[0m dw_coarse \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(dw_fine\u001b[38;5;241m.\u001b[39mreshape(sample_count, m_coarse, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdimension), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 259\u001b[0m s_fine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_sample_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdt_fine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdw_fine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m s_coarse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_sample_path(dt_coarse, dw_coarse)\n\u001b[1;32m    262\u001b[0m payoff_fine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontract\u001b[38;5;241m.\u001b[39mpayoff(s_fine)\n",
      "File \u001b[0;32m~/Developer/Projects/mlmc_simulation_path/notebooks/../src/mlmc.py:270\u001b[0m, in \u001b[0;36mMonteCarloEstimator._build_sample_path\u001b[0;34m(self, dt, dw)\u001b[0m\n\u001b[1;32m    268\u001b[0m s[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39minitial_value\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dw\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m--> 270\u001b[0m     drift \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrift\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     diffusion \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mapply_along_axis(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdiffusion(i \u001b[38;5;241m*\u001b[39m dt, x), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, arr\u001b[38;5;241m=\u001b[39ms[:, i])\n\u001b[1;32m    273\u001b[0m     s[:, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m s[:, i] \u001b[38;5;241m+\u001b[39m drift \u001b[38;5;241m*\u001b[39m dt \u001b[38;5;241m+\u001b[39m diffusion \u001b[38;5;241m*\u001b[39m dw[:, i]\n",
      "File \u001b[0;32m~/Developer/Projects/mlmc_simulation_path/.venv/lib/python3.13/site-packages/numpy/lib/_shape_base_impl.py:409\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m--> 409\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m res \u001b[38;5;241m=\u001b[39m transpose(buff, buff_permute)\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(res)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "targets_errors = np.array(\n",
    "    [\n",
    "        [0.001, 0.0005, 0.0002, 0.0001, 0.00005],\n",
    "        [0.001, 0.0005, 0.0002, 0.0001, 0.00005],\n",
    "        [0.002, 0.001, 0.0005, 0.0002, 0.0001],\n",
    "        [0.005, 0.002, 0.001, 0.0005, 0.0002],\n",
    "        [0.005, 0.0005, 0.0002, 0.0001, 0.00005],\n",
    "    ]\n",
    ")\n",
    "models = [bs, bs, bs, bs, heston]\n",
    "contracts = [ue_call, asian_call, lookback, digital, ue_call]\n",
    "\n",
    "params = zip(targets_errors, models, contracts)\n",
    "plots = []\n",
    "\n",
    "for target_errors, model, contract in params:\n",
    "    # plots.append(create_paper_plots(mc, model, contract, target_errors))\n",
    "    fig, _ = create_paper_plots(mc, model, contract, target_errors)\n",
    "    fig.show()\n",
    "    plt.show()\n",
    "\n",
    "# for fig, _ in plots:\n",
    "#     fig.show()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
